# -*- coding: utf-8 -*-
"""main

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d7fgc2CkbRQZltM6Ukj7Ofe2VcpJ_kaJ
"""

import sys
import warnings
import subprocess
import requests
from langchain_ollama import ChatOllama
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import SystemMessage, HumanMessage

warnings.filterwarnings("ignore")

def check_ollama_server():
    try:
        response = requests.get("http://localhost:11434")
        if response.status_code == 200:
            return True
    except requests.ConnectionError:
        return False
    return False

def initialize_bot():

    try:
        llm = ChatOllama(model="llama3.1", temperature=0)
    except Exception as e:
        print(f"Error initializing LLM: {e}")
        sys.exit(1)

    @tool
    def web_search(query: str):
        try:
            from langchain_community.tools import DuckDuckGoSearchRun
            search = DuckDuckGoSearchRun()
            return search.invoke(query)
        except Exception:
            return "Search failed."

    tools = [web_search]

    system_instruction = """
    You are a smart AI assistant and you are supposed to be talking in the most human way possible.
    Do not search on web for making a statement as "Searching for web" just for a fact or something related to what has already been told to you isnt human like behaviour.
    RULES:
    Greetings or general conversations should be taken care of without searching memory or web. If user is introducing himself or telling something about himself or somehting that is a fact just remember it and answer like a normal human conversation. And if it is a part memory based statement and partly a question needed to be searched then look for the keywords that just need to be searched and then look into the memory and answer accordingly.
    1. **Memory First:** If user is having a general conversation or has asked you a mathematical/logical/reasoning/analytocal question answer it without searching on web. If you think user is asking something that is personal and he did not talk about it before then say you dont know it.
    Before searching on web just think if you really need to check. That is, if you feel user is going to say something in the next statement then maybe search is not needed but extra information on his statement is needed so just ask about it nicely without searching the web.
    2. **External Facts:** Use 'web_search' for any of the questions user poses that has not been in your memory and is something that you are not trained for or if it is current affair or a fact or any news or anything happening in thre world that you dont have prior knowledge about.
    """

    sys_msg = SystemMessage(content=system_instruction)

    memory = MemorySaver()
    graph = create_react_agent(llm, tools=tools, checkpointer=memory)

    return graph, sys_msg

def run_chat_loop():

    if not check_ollama_server():
        print("Error: Ollama server is not running. Please run 'ollama serve' in a separate terminal.")
        sys.exit(1)

    graph, sys_msg = initialize_bot()

    print("\nBot Initialized. Type 'exit', 'quit', or 'bye' to stop.")
    print("-" * 50)

    config = {"configurable": {"thread_id": "Production-Session"}}

    while True:
        try:
            user_input = input("\nYou: ")
            if user_input.lower() in ["exit", "quit", "bye"]:
                print("Goodbye!")
                break

            print("Bot: ", end="", flush=True)

            inputs = {"messages": [sys_msg, HumanMessage(content=user_input)]}

            for event in graph.stream(inputs, config=config, stream_mode="values"):
                message = event["messages"][-1]

                if message.type == "ai" and message.content:
                    if not message.tool_calls:
                        print(message.content, end="", flush=True)

            print("")

        except Exception as e:
            print(f"\nError: {e}")

if __name__ == "__main__":
    run_chat_loop()